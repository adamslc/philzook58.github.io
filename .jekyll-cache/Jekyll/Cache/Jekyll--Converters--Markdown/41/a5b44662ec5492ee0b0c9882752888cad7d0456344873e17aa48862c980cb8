I"uë<p>Vectors are dang useful things, and any energy you put into them seems to pay off massive dividends.</p>

<p>Vectors and Linear Algebra are useful for:</p>

<ul>
  <li>2D, 3D, 4D geometry stuff. Computer graphics, physics etc.</li>
  <li>Least Squares Fitting</li>
  <li>Solving discretized PDEs</li>
  <li>Quantum Mechanics</li>
  <li>Analysis of Linear Dynamical Systems</li>
  <li>Probabilistic Transition Matrices</li>
</ul>

<p>There are certain analogies between Haskell Functors and Vectors that corresponds to a style of computational vector mathematics that I think is pretty cool and don‚Äôt see talked about much.</p>

<p>Due to the expressivity of its type system, Haskell has a first class notion of container that many other languages don‚Äôt. In particular, I‚Äôm referring to the fact that Haskell has higher kinded types <code class="language-plaintext highlighter-rouge">* -&gt; *</code> (types parametrized on other types) that you can refer to directly without filling them first. Examples in the standard library include <code class="language-plaintext highlighter-rouge">Maybe</code>, <code class="language-plaintext highlighter-rouge">[]</code>, <code class="language-plaintext highlighter-rouge">Identity</code>, <code class="language-plaintext highlighter-rouge">Const b</code>, and <code class="language-plaintext highlighter-rouge">Either b</code>. Much more vector-y feeling examples can be found in Kmett‚Äôs linear package <code class="language-plaintext highlighter-rouge">V0</code>, <code class="language-plaintext highlighter-rouge">V1</code>, <code class="language-plaintext highlighter-rouge">V2</code>, <code class="language-plaintext highlighter-rouge">V3</code>, <code class="language-plaintext highlighter-rouge">V4</code>. For example, the 4 dimensional vector type <code class="language-plaintext highlighter-rouge">V4</code></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;code&gt;data V4 a = V4 a a a a&lt;/code&gt;
</code></pre></div></div>

<p>This really isn‚Äôt such a strange, esoteric thing as it may appear. You wouldn‚Äôt blink an eye at the type</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;code&gt;struct V4 {
   double x, y, z, w;
}&lt;/code&gt;
</code></pre></div></div>

<p>in some other language. What makes Haskell special is how compositional and generic it is.  We can build thousand element structs with ease via composition. What we have here is an alternative to the paradigm of computational vectors ~ arrays. Instead we have computational vectors ~ structs. In principle, I see no reason why this couldn‚Äôt be as fast as arrays, although with current compiler expectations it probably isn‚Äôt.</p>

<p>Monoidal categories are a mathematical structure that models this analogy well. It has been designed by mathematicians for aesthetic elegance, and it seems plausible that following its example leads us to interesting, useful, and pleasant vector combinators. And I personally find something that tickles me about category theory.</p>

<p>So to get started, let‚Äôs talk a bit about functors.</p>

<h2 id="the-algebra-of-functors">The Algebra of Functors</h2>

<p>Functors in Haskell are a typeclass for containers. They allow you to map functions over all the items in the container. They are related to the categorical notion of functor, which is a mapping between categories.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;code&gt;type Container = * -&gt; * -- Note: This is actually a kind signature.
-- Kinds and types are the same thing in Haskell.&lt;/code&gt;
</code></pre></div></div>

<p>You can lift the <a href="http://www.philipzucker.com/linear-algebra-of-types">product and sum of types</a> to the product and sum of Functors which you may find in <a href="http://hackage.haskell.org/package/base-4.12.0.0/docs/Data-Functor-Product.html">Data.Functor.Product</a> and <a href="http://hackage.haskell.org/package/base-4.12.0.0/docs/Data-Functor-Sum.html">Data.Functor.Sum</a>.  This is analogous to the lifting of ordinary addition and multiplication to the addition and multiplication of polynomials, which are kind of like numbers with a ‚Äúhole‚Äù.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;code&gt;newtype Product f g a = Pair (f a , g a)
newtype Sum f g a = Sum (Either (f a) (g a))&lt;/code&gt;
</code></pre></div></div>

<p>Functors also compose. A container of containers of <code class="language-plaintext highlighter-rouge">a</code> is still a container of <code class="language-plaintext highlighter-rouge">a</code>. We can form composite containers by using the Compose newtype wrapper.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;code&gt;newtype Compose f g a = Compose (f (g a))&lt;/code&gt;
</code></pre></div></div>

<p>When you use this Compose newtype, instead of having to address the individual elements by using <code class="language-plaintext highlighter-rouge">fmap</code> twice, a single application of <code class="language-plaintext highlighter-rouge">fmap</code> will teleport you through both layers of the container.</p>

<p><code class="language-plaintext highlighter-rouge">Product</code>, <code class="language-plaintext highlighter-rouge">Sum</code>, and <code class="language-plaintext highlighter-rouge">Compose</code> are all binary operator on functors. The type constructor has kind</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;code&gt;{- Enter into ghci -}
:kind Compose ==&gt; (* -&gt; *) -&gt; (* -&gt; *) -&gt; (* -&gt; *)
:kind Product ==&gt; (* -&gt; *) -&gt; (* -&gt; *) -&gt; (* -&gt; *)
:kind Sum ==&gt; (* -&gt; *) -&gt; (* -&gt; *) -&gt; (* -&gt; *)&lt;/code&gt;
</code></pre></div></div>

<p>Some important other functors from the algebra of types perspective are  <code class="language-plaintext highlighter-rouge">Const Void a</code>, <code class="language-plaintext highlighter-rouge">Const () a</code>, and <code class="language-plaintext highlighter-rouge">Identity a</code>. These are identity elements for <code class="language-plaintext highlighter-rouge">Sum</code>, <code class="language-plaintext highlighter-rouge">Product</code>, and <code class="language-plaintext highlighter-rouge">Compose</code> respectively.</p>

<p>You can define mappings between containers that don‚Äôt depend on the specifics of their contents. These mappings can only rearrange, copy and forget items of their contained type. This can be enforced at the type level by the polymorphic type signature</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;code&gt;type f ~&gt; g = forall a. f a -&gt; g a&lt;/code&gt;
</code></pre></div></div>

<p>These mappings correspond in categorical terminology to <a href="https://bartoszmilewski.com/2015/04/07/natural-transformations/">natural transformations</a> between the functors <code class="language-plaintext highlighter-rouge">f</code> and <code class="language-plaintext highlighter-rouge">g</code>. There is a category where objects are Functors and morphisms are natural transformations. <code class="language-plaintext highlighter-rouge">Sum</code>, <code class="language-plaintext highlighter-rouge">Product</code>, and <code class="language-plaintext highlighter-rouge">Compose</code> all obeys the laws necessary to be a monoidal product on this category.</p>

<p>How the lifting of functions works for <code class="language-plaintext highlighter-rouge">Compose</code> is kind of neat.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;code&gt;mon_prod :: Functor f' =&gt; (f ~&gt; f') -&gt; (g ~&gt; g') -&gt; (Compose f g ~&gt; Compose f' g')
mon_prod ntf ntg (Compose fg) = Compose (fmap ntg (ntf fg))
-- or equvalently Compose (ntf (fmap ntg fg)) with a (Functor f) typeclass requirement.&lt;/code&gt;
</code></pre></div></div>

<p>Because the natural transformations require polymorphic types, when you apply <code class="language-plaintext highlighter-rouge">ntf</code> to <code class="language-plaintext highlighter-rouge">fg</code> the polymorphic variable <code class="language-plaintext highlighter-rouge">a</code> in the type of <code class="language-plaintext highlighter-rouge">ntf</code> restricts to <code class="language-plaintext highlighter-rouge">a ~ g a'</code>.</p>

<p><code class="language-plaintext highlighter-rouge">Product</code> and <code class="language-plaintext highlighter-rouge">Sum</code> have a straight forward notion of commutativity ( <code class="language-plaintext highlighter-rouge">(a,b)</code> is isomorphic to <code class="language-plaintext highlighter-rouge">(b,a)</code>) . <code class="language-plaintext highlighter-rouge">Compose</code> is more subtle. <code class="language-plaintext highlighter-rouge">sequenceA</code> from the Traversable typeclass can swap the ordering of composition. <code class="language-plaintext highlighter-rouge">sequenceA . sequenceA</code> may or may not be the identity depending on the functors in question, so it has some flavor of a braiding operation. This is an interesting post on that topic <a href="https://parametricity.com/posts/2015-07-18-braids.html">https://parametricity.com/posts/2015-07-18-braids.html</a></p>

<p>Combinators of these sorts are used arise in at least the following contexts</p>

<ul>
  <li><a href="http://www.cs.ru.nl/~W.Swierstra/Publications/DataTypesALaCarte.pdf">Data types a la carte</a> - A systematic way of building extensible data types</li>
  <li><a href="https://www.stackbuilders.com/tutorials/haskell/generics/">GHC Generics </a>- A system for building generic functions that operate on data types that can be described with sums, products, recursion, and holes.</li>
  <li>In and around the Lens ecosystem</li>
</ul>

<p>Also see the interesting post by Russell O‚ÄôConnor and functor oriented programming <a href="http://r6.ca/blog/20171010T001746Z.html">http://r6.ca/blog/20171010T001746Z.html</a>. I think the above is part of that to which he is referring.</p>

<h3 id="vector-spaces-as-shape">Vector Spaces as Shape</h3>

<p>Vector spaces are made of two parts, the shape (dimension) of the vector space and the scalar.</p>

<p>Just as a type of kind <code class="language-plaintext highlighter-rouge">* -&gt; *</code> can be thought of as a container modulo it‚Äôs held type, it can also be a vector modulo its held scalar type. The higher kinded type for vector gives an explicit slot to place the scalar type.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;code&gt;type Vect = * -&gt; *&lt;/code&gt;
</code></pre></div></div>

<p>The standard Haskell typeclass hierarchy gives you some of the natural operations on vectors if you so choose to abuse it in that way.</p>

<ul>
  <li>Functor ~&gt; Scalar Multiplication: <code class="language-plaintext highlighter-rouge">smul s = fmap (* s)</code></li>
  <li>Applicative ~&gt; Vector Addition:  vadd x y = (+) &lt;$&gt; x  &lt;*&gt; y</li>
  <li>Traversable ~&gt; Tranposition. <code class="language-plaintext highlighter-rouge">sequenceA</code> has the type of transposition and works correctly for the linear style containers like V4.</li>
</ul>

<p>The<a href="http://hackage.haskell.org/package/linear-1.20.9/docs/Linear-Vector.html"> linear library</a> does use <code class="language-plaintext highlighter-rouge">Functor</code> for scalar multiplication, but defines a special typeclass for addition, <code class="language-plaintext highlighter-rouge">Additive</code>. I think this is largely for the purposes for bringing <code class="language-plaintext highlighter-rouge">Map</code> like vectors into the fold, but I‚Äôm not sure.</p>

<p>Once we‚Äôve got the basics down of addition and scalar multiplication, the next thing I want is operations for combining vector spaces. Two important ones are the Kronecker product and direct sum. In terms of indices, the Kronecker product is a space that is indexed by the cartesian product <code class="language-plaintext highlighter-rouge">(,)</code> of its input space indices and the direct sum is a space indexed by the <code class="language-plaintext highlighter-rouge">Either</code> of its input space indices. Both are very useful constructs. I use the Kronecker product all the time when I want to work on 2D or 3D grids for example. If you‚Äôll excuse my python, here is a toy 2-D finite difference Laplace equation example. We can lift the 1D second derivative matrix $latex K = \partial_x^2 $ using the kronecker product $latex K2 = K \otimes I + I \otimes K$. The direct sum is useful as a notion of stacking matrices.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;code&gt;import numpy as np
N = 10 # We're making a 10x10 grid
row = np.zeros(N)
row[0] = -2
row[1] = 1
K = np.toeplitz(row,row) #toeplitz makes constant diagonal matrices
I = np.eye(N) #identity matrix
K2 = np.kron(K,I) + np.kron(I,K)&lt;/code&gt;
</code></pre></div></div>

<p>The following is perhaps the most important point of the entire post.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;code&gt;type Kron = Compose
type DSum = Product&lt;/code&gt;
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Compose</code> of vector functors gives the Kronecker product, and <code class="language-plaintext highlighter-rouge">Product</code> gives the direct sum (this can be confusing but its right. Remember, the sum in direct sum refers to the <em>indices</em>).</p>

<p>We can form the Kronecker product of vectors given a Functor constraint.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;code&gt;kron :: (Num a, Functor f, Functor g) =&gt; f a -&gt; g a -&gt; Kron f g a
kron f g = Compose $ fmap (\s1 -&gt; fmap (\s2 -&gt; s1 * s2) g) f

dsum :: f a -&gt; g a -&gt; DSum f g a
dsum f g = Pair f g&lt;/code&gt;
</code></pre></div></div>

<p>Notice we have two distinct but related things called kron: <code class="language-plaintext highlighter-rouge">Kron</code> and <code class="language-plaintext highlighter-rouge">kron</code>. One operates on vectors <em>spaces</em> and the other operates on vector <em>values</em>.</p>

<p>Building vector spaces out of small combinators like V2, V4, DSum, Kron is interesting for a number of reasons.</p>

<ul>
  <li>It is well typed. Similar to Nat indexed vectors, the types specify the size of the vector space. We can easily describe vector spaced as powers of 2 as <code class="language-plaintext highlighter-rouge">V16 =  Kron V2 (Kron V2 (Kron V2 (Kron V2 V1)))</code>, similarly in terms of its prime factors, or we can do a binary expansion (least significant bit first) <code class="language-plaintext highlighter-rouge">V5 = DSum V1 (Kron V2 (DSum V0 (Kron V2 V1)))</code> or other things. We do it without going into quasi-dependently typed land or GADTs.</li>
  <li>It often has better semantic meaning. It is nice to say Measurements, or XPosition or something rather than just denote the size of a vector space in terms of a nat. It is better to say a vector space is the Kron of two meaningful vector spaces than to just say it is a space of size m*n. I find it pleasant to think of the naturals as a free Semiring rather than as the Peano Naturals and I like the size of my vector space defined similarly.</li>
  <li>Interesting opportunities for parallelism. See Conal Elliott‚Äôs paper on scans and FFT: <a href="http://conal.net/papers/generic-parallel-functional/">http://conal.net/papers/generic-parallel-functional/</a></li>
</ul>

<h4 id="what-do-linear-operators-look-like">What do linear operators look like?</h4>

<p>In the Vectors as shape methodology, Vectors look very much like Functors.</p>

<p>I have been tempted to lift the natural transformation type above to the following for linear operators.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;code&gt;type LinOp f g = forall a. (Num a) =&gt; f a -&gt; g a&lt;/code&gt;
</code></pre></div></div>

<p>In a sense this works, we could implement <code class="language-plaintext highlighter-rouge">kron</code> because many of the container type (<code class="language-plaintext highlighter-rouge">V1</code>, <code class="language-plaintext highlighter-rouge">V2</code>, <code class="language-plaintext highlighter-rouge">V3</code>, etc) in the linear package implement Num. However, choosing Num is a problem. Why not Fractional? Why not Floating? Sometimes we want those. Why not just specifically Double?</p>

<p>We don‚Äôt really want to lock away the scalar in a higher rank polymorphic type. We want to ensure that everyone is working in the same scalar type before allowing things to proceed.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;code&gt;type LinOp f g a = f a -&gt; g a&lt;/code&gt;
</code></pre></div></div>

<p>Note also that this type does not constrain us to linearity. Can we form the Kronecker product of linear operators? Yes, but I‚Äôm not in love with it. This is not nearly so beautiful as the little natural transformation dance.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;code&gt;kron''' :: (Applicative f', Applicative g', Traversable f, Traversable g') =&gt;
    (f a -&gt; f' a) -&gt; (g a -&gt; g' a) -&gt; (Kron f g a -&gt; Kron f' g' a)
kron'' lf lg (Compose fga) = Compose $ sequenceA $ (fmap lf) $ sequenceA $ (fmap lg fga)&lt;/code&gt;
</code></pre></div></div>

<p>This was a nice little head scratcher for me. Follow the types, my friend! I find this particularly true for uses of <code class="language-plaintext highlighter-rouge">sequenceA</code>. I find that if I want the containers swapped in ordering. In that situation sequenceA is usually the right call. It could be called <code class="language-plaintext highlighter-rouge">transpose</code>.</p>

<p>Giving the vector direct access to the scalar feels a bit off to me. I feel like it doesn‚Äôt leave enough ‚Äúroom‚Äù for compositionally. However, there is another possibility for a definition of morphisms could be that I think is rather elegant.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;code&gt;type LinOp1 f g a = forall k. Additive k =&gt; Kron f k a -&gt; Kron g k a&lt;/code&gt;
</code></pre></div></div>

<p>Does this form actually enforce linearity? You may still rearrange objects. Great. You can also now add and scalar multiply them with the <code class="language-plaintext highlighter-rouge">Additive k</code> constraint. We also expose the scalar, so it can be enforced to be consistent.</p>

<p>One other interesting thing to note is that these forms allow nonlinear operations. <code class="language-plaintext highlighter-rouge">fmap</code>, <code class="language-plaintext highlighter-rouge">liftU2</code> and <code class="language-plaintext highlighter-rouge">liftI2</code> are powerful operations, but I think if we restricted <code class="language-plaintext highlighter-rouge">Additive</code> to just a correctly implemented scalar multiply and vector addition operation, and zero, we‚Äôd be good.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;code&gt;class Additive' f where
  smul :: Num a =&gt; a -&gt; f a -&gt; f a
  vadd :: Num a =&gt; f a -&gt; f a -&gt; f a
  zero :: Num a =&gt; f a&lt;/code&gt;
</code></pre></div></div>

<p>We can recover the previous form by instantiation <code class="language-plaintext highlighter-rouge">k</code> to <code class="language-plaintext highlighter-rouge">V1</code>. <code class="language-plaintext highlighter-rouge">V1</code>, the 1-d vector space, is almost a scalar and can play the scalars role in many situations. <code class="language-plaintext highlighter-rouge">V1</code> is the unit object with respect to the monoidal product <code class="language-plaintext highlighter-rouge">Kron</code>.</p>

<p>There seems to be a missing instance to Additive that is useful. There is probably a good reason it isn‚Äôt there, but I need it.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;code&gt;instance (Additive g, Additive f) =&gt; Additive (Compose f g) where
    (Compose v) ^+^ (Compose w) = Compose (liftU2 (^+^) v w)
    zero = zero
    liftU2 f (Compose x) (Compose y) = Compose $ liftU2 (liftU2 f) x y
    liftI2 f (Compose x) (Compose y) = Compose $ liftI2 (liftI2 f) x y&lt;/code&gt;
</code></pre></div></div>

<h2 id="monoidal-categories">Monoidal Categories</h2>

<p>The above analogy can be put into mathematical terms by noting that both vectors and functor are monoidal categories. I talked a quite a bit about monoidal categories in a previous post <a href="http://www.philipzucker.com/a-touch-of-topological-computation-3-categorical-interlude/">http://www.philipzucker.com/a-touch-of-topological-computation-3-categorical-interlude/</a> .</p>

<p>Categories are the combo of a collection of objects and arrows between the objects. The arrows can compose as long as the head of one is on the same object as the tail of the other. On every object, there is always an identity arrow, which when composed will do nothing.</p>

<p>We need a little extra spice to turn categories into monoidal categories. One way of thinking about it is that monoidal categories have ordinary category composition and some kind of horizontal composition, putting things side to side. Ordinary composition is often doing something kind of sequentially, applying a sequence of functions, or a sequence of matrices. The horizontal composition is often something parallel feeling, somehow applying the two arrows separately to separate pieces of the system.</p>

<h3 id="why-are-they-called-monoidal"><strong>Why are they called Monoidal?</strong></h3>

<p>There is funny game category people play where they want to lift ideas from other fields and replace the bits and pieces in such a way that the entire thing is defined in terms of categorical terminology. This is one such example.</p>

<p>A monoid is a binary operations that is associative and has an identity.</p>

<p>Sometimes people are more familiar with the concept of a group. If not, ignore the next sentence. Monoids are like groups without requiring an inverse.</p>

<p>Numbers are seperately monoids under both addition, multiplication and minimization (and more), all of which are associative operations with identity (0, 1, and infinity respectively).</p>

<p>Exponentiation is a binary operation that is not a monoid, as it isn‚Äôt associative.</p>

<p>The Monoid typeclass in Haskell demonstrates this <a href="http://hackage.haskell.org/package/base-4.12.0.0/docs/Data-Monoid.html">http://hackage.haskell.org/package/base-4.12.0.0/docs/Data-Monoid.html</a></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;code&gt;class Semigroup a =&gt; Monoid a where
        mempty  :: a
        mappend :: a -&gt; a -&gt; a&lt;/code&gt;
</code></pre></div></div>

<p>A common example of a monoid is list, where <code class="language-plaintext highlighter-rouge">mempty</code> is the empty list and <code class="language-plaintext highlighter-rouge">mappend</code> appends the lists.</p>

<p>There are different set-like intuitions for categories. One is that the objects in the category are big opaque sets. This is the case for Hask, Rel and Vect.</p>

<p>A different intuitiion is that the category itself is like a set, and the objects are the elements of that set. There just so happens to be some extra structure knocking around in there: the morphisms. This is the often more the feel for the examples of preorders or graphs. The word ‚Äúmonoidal‚Äù means that they we a binary operation on the objects. But in the category theory aesthetic, you also need that binary operation to ‚Äúplay nice‚Äù with the morphisms that are hanging around too.</p>

<p>Functors are the first thing that has something like this. It has other properties that come along for the ride. A Functor is a map that takes objects to objects and arrows to arrows in a nice way. A binary functor takes two objects to and object, and two arrows to one arrow in a way that plays nice (commutes) with arrow composition.</p>

<h3 id="string-diagrams"><strong>String diagrams</strong></h3>

<p><a href="https://en.wikipedia.org/wiki/String_diagram">String diagrams</a> are a graphical notation for monoidal categories. Agin I discussed this more <a href="http://www.philipzucker.com/a-touch-of-topological-computation-3-categorical-interlude/">here</a>.</p>

<p>Morphisms are denoted by boxes. Regular composition is shown by plugging arrows together vertically. Monoidal product is denoted by putting the arrows side to side.</p>

<p>When I was even trying to describe what a monoidal category was, I was already using language evocative of string diagrams.</p>

<p>You can see string diagrams in the <a href="https://en.wikibooks.org/wiki/Haskell/Understanding_arrows">documentation</a> for the Arrow library. Many diagrams that people use in various fields can be formalized as the string diagrams for some monoidal category. This is big chunk of Applied Category Theory.</p>

<p>This is the connection to quantum circuits, which are after all a graphical notation for very Kroneckery linear operations.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;code&gt;type Qubit = V2
type C = Complex Double

assoc :: Functor f =&gt; (Kron (Kron f g) h) ~&gt; (Kron f (Kron g h))
assoc = Compose . (fmap Compose) . getCompose . getCompose

assoc' :: Functor f =&gt;  (Kron f (Kron g h)) ~&gt; (Kron (Kron f g) h)
assoc' (Compose x)  = Compose $ Compose $ (fmap getCompose x) 

kron'' :: (Additive f, Additive g, Additive k, Additive f', Additive g') =&gt; 
  LinOp1 f f' a -&gt; LinOp1 g g' a -&gt; Kron (Kron f g) k a -&gt; Kron (Kron f' g') k a
kron'' lf lg fgk = let v = (assoc fgk) in assoc' (Compose $ fmap lg $ getCompose (lf v))

sigx' :: LinOp1 Qubit Qubit C 
sigx' (Compose (V2 up down)) = Compose $ V2 down up  

sigz' :: LinOp1 Qubit Qubit C 
sigz' (Compose (V2 up down)) = Compose  $ V2 up ((-1) *^ down) 

sigy' :: LinOp1 Qubit Qubit C 
sigy' (Compose (V2 up down)) = Compose $ V2 ((-i) *^ down) (i *^ up) where i = 0 :+ 1

swap' :: (Traversable f, Applicative g) =&gt; LinOp1 (Kron f g) (Kron g f) a 
swap' (Compose (Compose fgk)) = Compose $ Compose $ sequenceA fgk 

cnot :: LinOp1 (Kron Qubit Qubit) (Kron Qubit Qubit) a 
cnot (Compose (Compose (V2 (V2 up1 down1) v))) = Compose $ Compose $ V2 (V2 down1 up1) v

phase :: Double -&gt; LinOp1 Qubit Qubit C
phase phi (Compose (V2 up down)) = Compose $ V2 up ((cis phi) *^ down)

lefting :: (Additive f, Additive k, Additive g) =&gt; LinOp1 f g a -&gt; LinOp1 (Kron f k) (Kron g k) a
lefting l = kron'' l id -- Qubit.assoc' . l . Qubit.assoc 

righting :: (Additive k, Additive f, Additive g) =&gt; LinOp1 f g a -&gt; LinOp1 (Kron k f) (Kron k g) a
righting l = kron'' id l -- (Compose (Compose fkk)) = Compose $ Compose $ (fmap (getCompose . l . Compose) fkk)

example :: LinOp1 (Kron Qubit Qubit) (Kron Qubit Qubit) C 
example = (lefting sigx') . (lefting sigy') . (righting sigz') . swap'
&lt;/code&gt;
</code></pre></div></div>

<p><img src="http://philzucker2.nfshost.com/wp-content/uploads/2019/10/My-Drawing.sketchpad-546x1024.png" alt="" />example circuit</p>

<p>There is an annoying amount of stupid repetitive book keeping with the associative structure of Kron. This can largely be avoided hopefully with <code class="language-plaintext highlighter-rouge">coerce</code>, but I‚Äôm not sure. I was having trouble with roles when doing it generically.</p>

<h3 id="bit-and-bobbles">Bit and Bobbles</h3>

<ul>
  <li>Woof. This post was more draining to write than I expected. I think there is still a lot left to say. Sorry about the editing everyone! Bits and pieces of this post are scattered in this <a href="https://github.com/philzook58/fib-anyon">repo</a></li>
  <li>How would you go about this in other languages? C, Rust, OCaml, C++, Agda</li>
  <li>The discussion of Vect = * -&gt; * is useful for discussion of 2-Vect, coming up next. What if we make vectors of Vect? Wacky shit.</li>
  <li>Metrics and Duals vectors. <code class="language-plaintext highlighter-rouge">type Dual f a = f a -&gt; a</code>. <code class="language-plaintext highlighter-rouge">type Dual1 f a = forall k. Additive k =&gt; Kron f k a -&gt; k a</code></li>
  <li>Adjunction diagrams have cups and caps. Since we have been using representable functors, they actually have a right adjunction that is tupling with the vector space index type. This gives us something that almost feels like a metric but a weirdly constrained metric.</li>
  <li>LinOp1 form is yoneda? CPS? Universally quantified k is evocative of <code class="language-plaintext highlighter-rouge">forall c. (a -&gt; c) -&gt; (b -&gt; c)</code></li>
</ul>

<h3 id="references">References</h3>

<ul>
  <li>I got the LinOp1 construction from Kitaev <a href="https://arxiv.org/abs/cond-mat/0506438">https://arxiv.org/abs/cond-mat/0506438</a> Presumably there are better references as this is not the thrust of this massive article.</li>
  <li>Jeremy Gibbons Naperian Functor - Very interesting and related to this post. <a href="https://www.cs.ox.ac.uk/people/jeremy.gibbons/publications/aplicative.pdf">https://www.cs.ox.ac.uk/people/jeremy.gibbons/publications/aplicative.pdf</a></li>
  <li>Bartosz Milewski - String Diagrams  <a href="https://www.youtube.com/watch?v=eOdBTqY3-Og">https://www.youtube.com/watch?v=eOdBTqY3-Og</a></li>
  <li>Huenen and Vicary - <a href="http://www.cs.ox.ac.uk/people/jamie.vicary/IntroductionToCategoricalQuantumMechanics.pdf">http://www.cs.ox.ac.uk/people/jamie.vicary/IntroductionToCategoricalQuantumMechanics.pdf</a> Intro to categorical quantum mechanics.</li>
  <li><a href="http://hackage.haskell.org/package/linear">http://hackage.haskell.org/package/linear</a> Kmett‚Äôs linear package</li>
  <li><a href="https://graphicallinearalgebra.net/">https://graphicallinearalgebra.net/</a> - Graphical Linear Algebra</li>
  <li><a href="http://www.philipzucker.com/resources-string-diagrams-adjunctions-kan-extensions/">http://www.philipzucker.com/resources-string-diagrams-adjunctions-kan-extensions/</a></li>
  <li><a href="http://www.philipzucker.com/functor-vector-part-2-function-vectors/">http://www.philipzucker.com/functor-vector-part-2-function-vectors/</a></li>
  <li><a href="http://www.philipzucker.com/functor-vector-part-1-functors-basis/">http://www.philipzucker.com/functor-vector-part-1-functors-basis/</a></li>
  <li>Baez and Stay. Rosetta Stone. A classic <a href="http://math.ucr.edu/home/baez/rosetta.pdf">http://math.ucr.edu/home/baez/rosetta.pdf</a></li>
</ul>

<h2 id="appendix">Appendix</h2>

<h3 id="representablenaperian-functors">Representable/Naperian Functors</h3>

<p>Containers that are basically big product types are also known as representable, Naperian, or logarithmic. Representable places emphasis on the isomorphism between such a container type and the type <code class="language-plaintext highlighter-rouge">(-&gt;) i</code> which by the algebra of types correspond is isomorphic to $latex a^i$ (i copies of a). They are called Naperian/Logarithmic because there is a relationship similar to exponentiation between the index type <code class="language-plaintext highlighter-rouge">a</code> and the container type <code class="language-plaintext highlighter-rouge">f</code>. If you take the <code class="language-plaintext highlighter-rouge">Product f g</code>, this container is indexed by (a + b) = <code class="language-plaintext highlighter-rouge">Either a b</code>.  <code class="language-plaintext highlighter-rouge">Compose f g</code> is indexed by the product <code class="language-plaintext highlighter-rouge">(a,b)</code>. <code class="language-plaintext highlighter-rouge">(f r) ~ r^a</code> The arrow type is written as an exponential <code class="language-plaintext highlighter-rouge">b^a</code> because if you have finite enumerable types <code class="language-plaintext highlighter-rouge">a</code> and <code class="language-plaintext highlighter-rouge">b</code>, that is the number of possible tabulations available for <code class="language-plaintext highlighter-rouge">f</code>. The Sum of two representable functors is no longer representable. Regular logarithms of sums Log(f + g) do not have good identities associated with them.</p>

<p>See Gibbons article. There is a good argument to be made that representable functors are a good match for vectors/well typed tensor programming.</p>

<p>But note that there is a reasonable interpretation for container types with sum types in them. These can be thought of as subspaces, different bases, or as choices of sparsity patterns. When you define addition, you‚Äôll need to say how these subspaces reconcile with each other.<br />
‚Äì two bases at 45 degrees to each other.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;code&gt;data V2_45 a = XY a a | XY' a a
data Maybe a = Just a | Notinhg -- a 1-d vectro space with a special marker for the zero vector.
data Maybe2 a = Just2 a a | Nothing2 -- a 2d vector space with special zero marker&lt;/code&gt;
</code></pre></div></div>

<p>https://bartoszmilewski.com/2015/07/29/representable-functors/</p>

<h3 id="monoidal-products-on-hask"><strong>Monoidal Products on Hask</strong></h3>

<p>Hask is a name for the category that has objects as Haskell types and morphisms as Haskell functions.</p>

<p>Note that it‚Äôs a curious mixing of type/value layers of Haskell.  The objects are types whereas the function morphisms are Haskell values. Composition is given by <code class="language-plaintext highlighter-rouge">(.)</code> and the identity morphisms are given by <code class="language-plaintext highlighter-rouge">id</code>.</p>

<p>For Haskell, you can compose functions, but you can also smash functions together side by side. These combinators are held in <a href="http://hackage.haskell.org/package/base-4.12.0.0/docs/Control-Arrow.html">Control.Arrow</a>.</p>

<p>You can smash together types with tuple <code class="language-plaintext highlighter-rouge">(,)</code> or with <code class="language-plaintext highlighter-rouge">Either</code>. Both of these are binary operators on types. The corresponding mapping on morphisms are given by</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;code&gt;(***) :: a b c -&gt; a b' c' -&gt; a (b, b') (c, c') 
(+++) :: a b c -&gt; a b' c' -&gt; a (Either b b') (Either c c') &lt;/code&gt;
</code></pre></div></div>

<p>These are binary operators on morphisms that play nice with the composition structure of Haskell.</p>

<h3 id="monoidal-combinators-of-functors">Monoidal Combinators of Functors</h3>

<p>A monoidal category also has unit objects. This is given by the Identity functor</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;code&gt;rightUnitor :: Functor f =&gt; Compose f Identity a -&gt; f a
rightUnitor (Compose f) = fmap runIdentity f

rightUnitor' :: f ~&gt; Compose f Identity
rightUnitor' = Compose . fmap Identity

leftUnitor' :: f ~&gt; Compose Identity f
leftUnitor' = Compose . Identity

leftUnitor :: Identity *** f ~&gt; f
leftUnitor = runIdentity . getCompose&lt;/code&gt;
</code></pre></div></div>

<p>There is also a sense of associativity. It is just newtype rearrangement, so it can also be achieved with a <code class="language-plaintext highlighter-rouge">coerce</code> (although not polymorphically?).</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;code&gt;assoc :: Functor f =&gt; ((f *** g) *** h) ~&gt; (f *** (g *** h))
assoc = Compose . (fmap Compose) . getCompose . getCompose

assoc' :: Functor f =&gt; (f *** (g *** h)) ~&gt; ((f *** g) *** h)
assoc' (Compose x) = Compose $ Compose $ (fmap getCompose x)&lt;/code&gt;
</code></pre></div></div>

<p>Similarly, we can define a monoidal category structure using Product or Sum instead of Compose.</p>

<p>These are all actually just newtype rearrangement, so they should all just be instances of <code class="language-plaintext highlighter-rouge">coerce</code>, but I couldn‚Äôt get the roles to go through generically?</p>

:ET